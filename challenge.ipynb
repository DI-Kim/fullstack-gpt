{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "  temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "loader = UnstructuredFileLoader(\"./files/document.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 캐시가 저장되어 있는지 확인\n",
    "# 저장되어 있으면 캐시에서 가져오고, 저장되어있지 않으면 캐시로 저장함\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "  embeddings, cache_dir\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "def load_memory(input):\n",
    "  return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  (\"system\", \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\"),\n",
    "  MessagesPlaceholder(variable_name='history'),\n",
    "  (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain =  {\"context\": retriever, \"question\": RunnablePassthrough()} | RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "  result = chain.invoke(question)\n",
    "  memory.save_context({\"input\": question}, {\"output\": result.content})\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='제가 알기로는 Aaronson이 유죄인지 아닌지에 대한 정보는 제공되지 않았습니다.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('Aaronson은 유죄인가요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Aaronson은 유죄인가요?'),\n",
       "  AIMessage(content='제가 알기로는 Aaronson이 유죄인지 아닌지에 대한 정보는 제공되지 않았습니다.')]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='그가 쓴 메시지는 다음과 같습니다:\\nFREEDOM IS SLAVERY\\nTWO AND TWO MAKE FIVE\\nGOD IS POWER'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('그가 테이블에 어떤 메시지를 썼나요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Aaronson은 유죄인가요?'),\n",
       "  AIMessage(content='제가 알기로는 Aaronson이 유죄인지 아닌지에 대한 정보는 제공되지 않았습니다.'),\n",
       "  HumanMessage(content='그가 테이블에 어떤 메시지를 썼나요?'),\n",
       "  AIMessage(content='그가 쓴 메시지는 다음과 같습니다:\\nFREEDOM IS SLAVERY\\nTWO AND TWO MAKE FIVE\\nGOD IS POWER')]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Julia는 주인공과 함께 이야기하는 여성 캐릭터입니다.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('Julia는 누구인가요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Julia는 누구인가요?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain('제가 방금 한 질문이 뭐였죠?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
